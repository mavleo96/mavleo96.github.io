<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Whisper Accent | Vijayabharathi Murugan </title> <meta name="author" content="Vijayabharathi Murugan"> <meta name="description" content="Conditioning via adaptive layer normalization for accent-aware English speech recognition"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mavleo96.github.io/projects/whisper-accent/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Vijayabharathi</span> Murugan </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Whisper Accent</h1> <p class="post-description">Conditioning via adaptive layer normalization for accent-aware English speech recognition</p> </header> <article> <p>Despite impressive multilingual performance, state-of-the-art ASR models like Whisper continue to exhibit elevated word error rates (WER) on non-native and regionally diverse English accents. Training a separate adapter per accent is expensive and brittle: it demands sufficient labelled data for each accent, scales poorly, and discards the shared phonological structure that spans accent families.</p> <p>We present <strong>Whisper-Accent</strong>: an extension of pretrained Whisper that handles 23 phonetically diverse English accents in a single model by conditioning the frozen decoder on per-accent learned embeddings via <strong>Adaptive Layer Normalization (AdaLN)</strong>. Only the AdaLN modulation weights, accent embeddings, and accent classifier are trained from scratch; the encoder and decoder backbone remain completely frozen. Whisper-Accent achieves <strong>14.1% WER</strong> (<code class="language-plaintext highlighter-rouge">whisper-accent-small.en</code>) and <strong>13.4% WER</strong> (<code class="language-plaintext highlighter-rouge">whisper-accent-medium.en</code>) compared to 17.6% and 17.5% for the respective Whisper baselines — absolute improvements of <strong>3.5 and 4.1 percentage points</strong>.</p> <hr> <h2 id="architecture">Architecture</h2> <div class="row justify-content-sm-center"> <div class="col-sm-10 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/whisper-accent/architecture-480.webp 480w,/assets/img/projects/whisper-accent/architecture-800.webp 800w,/assets/img/projects/whisper-accent/architecture-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/whisper-accent/architecture.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Whisper-Accent Architecture" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 1: Whisper-Accent architecture. The encoder predicts the accent label; the corresponding embedding conditions every frozen decoder LayerNorm via AdaLN. </div> <p><strong>Accent Classifier.</strong> The encoder produces hidden states at every layer. We learn scalar fusion weights over all \(L\) encoder layers plus the input embedding, yielding a weighted-average representation of shape \((T, D)\). A linear projection reduces dimensionality, and multi-head attention pooling (MHA-pool) collapses the temporal axis via a learnable query vector. The resulting fixed-length vector is passed to a linear classification head over \(A\) accent classes.</p> <p><strong>Accent Embeddings.</strong> A lookup table of \(A\) trainable vectors maps a predicted accent label to a conditioning vector \(e \in \mathbb{R}^d\). Ground-truth labels are used during training; predicted labels from the classifier are used at inference, making the system fully self-contained.</p> <p><strong>Adaptive Layer Normalization.</strong> AdaLN was popularized in class-conditional diffusion transformers as a way to condition generation on a class embedding without modifying the attention or feed-forward weights — the same principle we adopt here for accent conditioning. Every LayerNorm in the Whisper decoder is replaced by an AdaLN module:</p> \[\text{AdaLN}(h, e) = \big(1 + \gamma(e)\big) \odot \text{LayerNorm}(h) + \beta(e)\] <p>where \(\gamma(\cdot)\) and \(\beta(\cdot)\) are learned linear projections from the accent embedding. Projection weights are zero-initialized (following ControlNet), so AdaLN has no effect at the start of training. Bias projections are initialized to the pretrained LayerNorm \(\gamma\) / \(\beta\) values and frozen. Routing modulation through LayerNorm allows all accents to share the full backbone capacity while each steers the decoder’s representational manifold independently. Because the backbone is entirely frozen, the model preserves Whisper’s original generalization capability for accents outside the training distribution.</p> <hr> <h2 id="two-stage-training">Two-Stage Training</h2> <p>Training is split into two stages to manage the large difference in gradient norms between the randomly initialized accent classifier and the zero-initialized AdaLN weights.</p> <p><strong>Stage 1 — Accent Classifier.</strong> Only the layer-fusion weights, projection, MHA pooling, and classification head are trained under pure accent cross-entropy (\(\lambda_\text{CE} = 0\), \(\lambda_\text{accent} = 1\)) with class weighting to handle label imbalance. Learning rate: <code class="language-plaintext highlighter-rouge">1e-3</code>.</p> <p><strong>Stage 2 — Decoder AdaLN + Accent Embeddings.</strong> From the Stage 1 checkpoint, only the AdaLN modulation parameters and accent embedding table are unfrozen. Training uses pure ASR cross-entropy (\(\lambda_\text{CE} = 1\), \(\lambda_\text{accent} = 0\)) conditioned on ground-truth accent labels. Learning rate: <code class="language-plaintext highlighter-rouge">5e-5</code> for AdaLN; <code class="language-plaintext highlighter-rouge">5e-4</code> for accent embeddings. Weight decay is disabled, consistent with zero-initialized weights.</p> <hr> <h2 id="results">Results</h2> <p>All models are trained and evaluated on the <a href="https://huggingface.co/datasets/westbrook/English_Accent_DataSet" rel="external nofollow noopener" target="_blank">westbrook/English_Accent_DataSet</a>, a 79-hour speech corpus covering 23 English accents sourced from VCTK, EDACC, and VoxPopuli, with 50.4k training, 1.04k validation, and 1.62k test utterances. All results are on the test split.</p> <h3 id="comparison-with-whisper-baselines">Comparison with Whisper Baselines</h3> <p>A single Whisper-Accent model outperforms both vanilla Whisper baselines and a stronger fine-tuned baseline (decoder LayerNorm fine-tuning) — and even the much larger <code class="language-plaintext highlighter-rouge">whisper-large-v3</code> — demonstrating that accent conditioning is a more effective lever than raw model scale or naive adaptation.</p> <div class="row justify-content-center"> <div class="col-sm-8"> <table> <thead> <tr> <th style="text-align: left">Model</th> <th style="text-align: center">Overall WER ↓</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><em>Whisper Baselines</em></td> <td style="text-align: center"> </td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">whisper-small.en</code></td> <td style="text-align: center">17.6%</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">whisper-medium.en</code></td> <td style="text-align: center">17.5%</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">whisper-large-v3</code></td> <td style="text-align: center">17.7%</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">whisper-large-v3-turbo</code></td> <td style="text-align: center">20.1%</td> </tr> <tr> <td style="text-align: left"><em>Decoder LayerNorm Fine-tuned</em></td> <td style="text-align: center"> </td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">whisper-small.en</code></td> <td style="text-align: center">17.2%</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">whisper-medium.en</code></td> <td style="text-align: center">16.6%</td> </tr> <tr> <td style="text-align: left"><em>Whisper-Accent (Ours)</em></td> <td style="text-align: center"> </td> </tr> <tr> <td style="text-align: left"><strong><code class="language-plaintext highlighter-rouge">whisper-accent-small.en</code></strong></td> <td style="text-align: center"> <strong>14.1%</strong> (↓3.5pp)</td> </tr> <tr> <td style="text-align: left"><strong><code class="language-plaintext highlighter-rouge">whisper-accent-medium.en</code></strong></td> <td style="text-align: center"> <strong>13.4%</strong> (↓4.1pp)</td> </tr> </tbody> </table> </div> </div> <div class="caption"> Table 1: Overall WER on the English Accent Dataset test split. LayerNorm fine-tuned refers to fine-tuning decoder LayerNorm parameters without accent conditioning. </div> <h3 id="per-accent-wer-and-accent-classification-accuracy">Per-Accent WER and Accent Classification Accuracy</h3> <p>Improvements are observed across all 23 accent classes. The classifier achieves 95.7% accuracy on <code class="language-plaintext highlighter-rouge">whisper-accent-medium.en</code> and 85.1% on <code class="language-plaintext highlighter-rouge">whisper-accent-small.en</code>. Native varieties reach near-perfect transcription (American: 1.2%, Canadian: 0.8%), while phonologically distant accents remain challenging — Vietnamese: 32.3%, Indian English: 61.4%, the latter likely compounded by a small test set (n=51).</p> <div class="row justify-content-center"> <div class="col-sm-6"> <table> <thead> <tr> <th style="text-align: left">Accent</th> <th style="text-align: center">WER ↓</th> <th style="text-align: center">Accent Acc. ↑</th> <th style="text-align: center">n</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">English</td> <td style="text-align: center">5.2%</td> <td style="text-align: center">95.7%</td> <td style="text-align: center">442</td> </tr> <tr> <td style="text-align: left">American</td> <td style="text-align: center">1.2%</td> <td style="text-align: center">97.7%</td> <td style="text-align: center">263</td> </tr> <tr> <td style="text-align: left">Scottish</td> <td style="text-align: center">6.9%</td> <td style="text-align: center">94.9%</td> <td style="text-align: center">235</td> </tr> <tr> <td style="text-align: left">Irish</td> <td style="text-align: center">9.7%</td> <td style="text-align: center">97.4%</td> <td style="text-align: center">152</td> </tr> <tr> <td style="text-align: left">Canadian</td> <td style="text-align: center">0.8%</td> <td style="text-align: center">100.0%</td> <td style="text-align: center">90</td> </tr> <tr> <td style="text-align: left">Northern Irish</td> <td style="text-align: center">2.8%</td> <td style="text-align: center">94.5%</td> <td style="text-align: center">73</td> </tr> <tr> <td style="text-align: left">Indian</td> <td style="text-align: center">61.4%</td> <td style="text-align: center">100.0%</td> <td style="text-align: center">51</td> </tr> <tr> <td style="text-align: left">Spanish</td> <td style="text-align: center">14.8%</td> <td style="text-align: center">95.7%</td> <td style="text-align: center">46</td> </tr> <tr> <td style="text-align: left">Dutch</td> <td style="text-align: center">17.2%</td> <td style="text-align: center">100.0%</td> <td style="text-align: center">35</td> </tr> <tr> <td style="text-align: left">Polish</td> <td style="text-align: center">14.8%</td> <td style="text-align: center">96.8%</td> <td style="text-align: center">31</td> </tr> <tr> <td style="text-align: left">Italian</td> <td style="text-align: center">8.6%</td> <td style="text-align: center">86.2%</td> <td style="text-align: center">29</td> </tr> <tr> <td style="text-align: left">French</td> <td style="text-align: center">21.8%</td> <td style="text-align: center">73.1%</td> <td style="text-align: center">26</td> </tr> </tbody> </table> </div> <div class="col-sm-6"> <table> <thead> <tr> <th style="text-align: left">Accent</th> <th style="text-align: center">WER ↓</th> <th style="text-align: center">Accent Acc. ↑</th> <th style="text-align: center">n</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">Romanian</td> <td style="text-align: center">14.3%</td> <td style="text-align: center">91.3%</td> <td style="text-align: center">23</td> </tr> <tr> <td style="text-align: left">Estonian</td> <td style="text-align: center">12.4%</td> <td style="text-align: center">100.0%</td> <td style="text-align: center">13</td> </tr> <tr> <td style="text-align: left">Vietnamese</td> <td style="text-align: center">32.3%</td> <td style="text-align: center">100.0%</td> <td style="text-align: center">14</td> </tr> <tr> <td style="text-align: left">German</td> <td style="text-align: center">18.1%</td> <td style="text-align: center">96.3%</td> <td style="text-align: center">27</td> </tr> <tr> <td style="text-align: left">Czech</td> <td style="text-align: center">10.1%</td> <td style="text-align: center">94.7%</td> <td style="text-align: center">19</td> </tr> <tr> <td style="text-align: left">Slovak</td> <td style="text-align: center">7.3%</td> <td style="text-align: center">94.1%</td> <td style="text-align: center">17</td> </tr> <tr> <td style="text-align: left">Hungarian</td> <td style="text-align: center">9.7%</td> <td style="text-align: center">83.3%</td> <td style="text-align: center">18</td> </tr> <tr> <td style="text-align: left">Finnish</td> <td style="text-align: center">8.6%</td> <td style="text-align: center">81.8%</td> <td style="text-align: center">11</td> </tr> <tr> <td style="text-align: left">Lithuanian</td> <td style="text-align: center">2.7%</td> <td style="text-align: center">100.0%</td> <td style="text-align: center">2</td> </tr> <tr> <td style="text-align: left">Croatian</td> <td style="text-align: center">21.8%</td> <td style="text-align: center">100.0%</td> <td style="text-align: center">2</td> </tr> <tr> <td style="text-align: left">Slovene</td> <td style="text-align: center">6.1%</td> <td style="text-align: center">0.0%</td> <td style="text-align: center">1</td> </tr> <tr> <td style="text-align: left"><strong>Overall</strong></td> <td style="text-align: center"><strong>13.4%</strong></td> <td style="text-align: center"><strong>95.7%</strong></td> <td style="text-align: center"><strong>1620</strong></td> </tr> </tbody> </table> </div> </div> <div class="caption"> Table 2: Per-accent WER and classifier accuracy for whisper-accent-medium.en on the test split. n = number of test samples. </div> <h3 id="ablation-ground-truth-vs-predicted-vs-random-accent-labels">Ablation: Ground-Truth vs. Predicted vs. Random Accent Labels</h3> <div class="row justify-content-center"> <div class="col-sm-8"> <table> <thead> <tr> <th style="text-align: left">Conditioning</th> <th style="text-align: center">WER (small)</th> <th style="text-align: center">WER (medium)</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">Ground-truth accent label</td> <td style="text-align: center">14.2%</td> <td style="text-align: center">13.4%</td> </tr> <tr> <td style="text-align: left"><strong>Predicted accent label</strong></td> <td style="text-align: center"><strong>14.1%</strong></td> <td style="text-align: center"><strong>13.4%</strong></td> </tr> <tr> <td style="text-align: left">Random accent label</td> <td style="text-align: center">16.6%</td> <td style="text-align: center">15.1%</td> </tr> </tbody> </table> </div> </div> <div class="caption"> Table 3: WER under different accent conditioning strategies at evaluation time. </div> <p>Random conditioning still outperforms vanilla Whisper (16.6% / 15.1% vs. 17.6% / 17.5%), which is expected: with minimum pairwise embedding similarity of ~0.4, a randomly drawn embedding acts as a noisy weighted average over the embedding cluster rather than a true null. The gap between random and predicted conditioning (2.5 pp / 1.7 pp) therefore quantifies the net contribution of accurate accent classification. The near-zero gap between predicted and ground-truth (0.0–0.1 pp) confirms that the Stage 1 classifier effectively matches oracle performance.</p> <hr> <h2 id="accent-embedding-analysis">Accent Embedding Analysis</h2> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/whisper-accent/embedding_cosine_similarity-480.webp 480w,/assets/img/projects/whisper-accent/embedding_cosine_similarity-800.webp 800w,/assets/img/projects/whisper-accent/embedding_cosine_similarity-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/whisper-accent/embedding_cosine_similarity.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Cosine similarity heatmap of accent embeddings" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/whisper-accent/embedding_umap_projection-480.webp 480w,/assets/img/projects/whisper-accent/embedding_umap_projection-800.webp 800w,/assets/img/projects/whisper-accent/embedding_umap_projection-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/whisper-accent/embedding_umap_projection.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="UMAP projection of accent embeddings" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 2: Left — cosine similarity matrix of the 23 learned accent embeddings (whisper-accent-medium.en). Right — UMAP projection of the same embeddings. Broad groupings emerge from WER supervision alone, but low-resource accents show clear collapse artifacts. </div> <p>The cosine similarity heatmap shows a broad block-diagonal structure: native English varieties form the tightest cluster, a second block covers Central and Western European accents, and the Baltic/Southeast European group together with Vietnamese forms a third with notably lower similarity to native English. These groupings emerge from WER supervision alone — accents requiring similar decoder adjustments converge to similar embeddings, broadly tracking linguistic relatedness.</p> <p>The UMAP projection exposes two failure modes. First, Vietnamese (n=14) and Indian (n=51) collapse onto the native English cluster despite being phonologically the most distant — a data scarcity artefact; the heatmap, which captures angular distance rather than absolute coordinates, correctly places Vietnamese in the Baltic/Southeast European block and shows Indian at only moderate similarity (~0.5–0.6) to the British Isles group, confirming their embeddings have not fully converged. Second, Dutch, German, French, and Polish — three distinct language families — collapse into a single tight cluster, indicating that accents with similar WER difficulty profiles produce indistinguishable gradient updates under a WER-only objective regardless of phonological distance.</p> <hr> <h2 id="conclusion">Conclusion</h2> <p>Whisper-Accent shows that phonetically diverse accents can be handled within a single model by conditioning a frozen Whisper decoder on per-accent embeddings via AdaLN, eliminating the need for per-accent adapters. The approach works well for data-rich accents but the embedding analysis reveals a clear boundary condition: the WER objective alone cannot separate embeddings when training data is scarce or accent error profiles are confounded. Addressing this will require contrastive embedding objectives and more balanced accent coverage than current datasets provide. Code and pretrained checkpoints are available at <a href="https://github.com/mavleo96/whisper-accent" rel="external nofollow noopener" target="_blank">github.com/mavleo96/whisper-accent</a>.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Vijayabharathi Murugan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>
<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Whisper Accent | Vijayabharathi Murugan </title> <meta name="author" content="Vijayabharathi Murugan"> <meta name="description" content="Conditioning via Adaptive Layer Normalization for Accent-Aware English Speech Recognition"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mavleo96.github.io/projects/1_project/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Vijayabharathi</span> Murugan </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Whisper Accent</h1> <p class="post-description">Conditioning via Adaptive Layer Normalization for Accent-Aware English Speech Recognition</p> </header> <article> <p>Despite impressive multilingual performance, state-of-the-art ASR models like Whisper continue to exhibit elevated word error rates (WER) on non-native and regionally diverse English accents. Phonological variation across accents — differences in vowel quality, prosody, consonant realization, and rhythm — is systematic and structured. A model explicitly aware of speaker accent should be better equipped to attend to the relevant acoustic features.</p> <p>We present <strong>Whisper-Accent</strong>: an extension of pretrained Whisper that conditions the decoder on learned accent embeddings via <strong>Adaptive Layer Normalization (AdaLN)</strong>. The backbone encoder and decoder remain completely frozen, with only the AdaLN modulation weights, accent embeddings, and accent classifier trained from scratch. Whisper-Accent achieves <strong>14.1% WER</strong> (<code class="language-plaintext highlighter-rouge">whisper-accent-small.en</code>) and <strong>13.4% WER</strong> (<code class="language-plaintext highlighter-rouge">whisper-accent-medium.en</code>) compared to 17.6% and 17.5% for the respective Whisper baselines — absolute improvements of <strong>3.5 and 4.1 percentage points</strong>.</p> <hr> <h2 id="architecture">Architecture</h2> <p>The core idea is simple: instead of fine-tuning the backbone, we inject accent-specific conditioning into the decoder’s normalization layers. Three lightweight components are added on top of a frozen Whisper checkpoint.</p> <div class="row justify-content-sm-center"> <div class="col-sm-10 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/whisper-accent/architecture-480.webp 480w,/assets/img/whisper-accent/architecture-800.webp 800w,/assets/img/whisper-accent/architecture-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/whisper-accent/architecture.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Whisper-Accent Architecture" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 1: Whisper-Accent architecture. Accent embeddings are predicted from encoder hidden states via layer-weighted fusion and multi-head attention pooling, then used to modulate every frozen decoder LayerNorm via Adaptive Layer Normalization (AdaLN). </div> <p><strong>Accent Classifier.</strong> The encoder produces hidden states at every layer. We learn a set of scalar fusion weights over all \(L\) encoder layers plus the input embedding, yielding a single weighted-average representation of shape \((T, D)\). A linear projection reduces dimensionality, and multi-head attention pooling (MHA-pool) collapses the temporal axis using a learnable query vector. The resulting fixed-length vector is passed to a linear classification head over \(A\) accent classes.</p> <p><strong>Accent Embeddings.</strong> A lookup table of \(A\) trainable embedding vectors — one per accent class — maps a predicted accent label to a conditioning vector \(e \in \mathbb{R}^d\). Ground-truth labels are used during training; predicted labels from the classifier are used at inference, making the system fully self-contained.</p> <p><strong>Adaptive Layer Normalization.</strong> Every LayerNorm in the Whisper decoder is replaced by an AdaLN module:</p> \[\text{AdaLN}(h, e) = \big(1 + \gamma(e)\big) \odot \text{LayerNorm}(h) + \beta(e)\] <p>where \(\gamma(\cdot)\) and \(\beta(\cdot)\) are learned linear projections from the accent embedding. Projection weights are <strong>zero-initialized</strong> (following ControlNet (missing reference)), so AdaLN has no effect at the start of training — providing a stable, non-destructive initialization. Bias projections are initialized to the pretrained LayerNorm \(\gamma\) / \(\beta\) values and frozen.</p> <hr> <h2 id="two-stage-training">Two-Stage Training</h2> <p>Training decouples accent classification from ASR conditioning to avoid conflicting gradient signals.</p> <p><strong>Stage 1 — Accent Classifier.</strong> The full Whisper backbone is frozen. Only the layer-fusion weights, projection, MHA pooling, and classification head are trained under pure accent cross-entropy loss (\(\lambda_\text{CE} = 0\), \(\lambda_\text{accent} = 1\)). A learning rate of <code class="language-plaintext highlighter-rouge">1e-3</code> is used with class weighting to handle label imbalance.</p> <p><strong>Stage 2 — Decoder AdaLN + Accent Embeddings.</strong> The Stage 1 checkpoint is loaded; everything except the AdaLN modulation parameters and the accent embedding table is frozen. The model is trained under pure ASR cross-entropy (\(\lambda_\text{CE} = 1\), \(\lambda_\text{accent} = 0\)) conditioned on ground-truth accent labels. A primary learning rate of <code class="language-plaintext highlighter-rouge">5e-5</code> applies to AdaLN parameters; a separate embedding learning rate of <code class="language-plaintext highlighter-rouge">5e-4</code> applies to accent embeddings. Weight decay is disabled, consistent with zero-initialized AdaLN weights.</p> <hr> <h2 id="results">Results</h2> <h3 id="comparison-with-whisper-baselines">Comparison with Whisper Baselines</h3> <p>Whisper-Accent consistently outperforms its size-matched baselines — and even the much larger <code class="language-plaintext highlighter-rouge">whisper-large-v3</code> — demonstrating that targeted accent conditioning is a more effective lever than raw model scale.</p> <table> <thead> <tr> <th style="text-align: left">Model</th> <th style="text-align: center">Overall WER ↓</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">openai/whisper-small.en</code></td> <td style="text-align: center">17.6%</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">openai/whisper-medium.en</code></td> <td style="text-align: center">17.5%</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">openai/whisper-large-v3</code></td> <td style="text-align: center">17.7%</td> </tr> <tr> <td style="text-align: left"><code class="language-plaintext highlighter-rouge">openai/whisper-large-v3-turbo</code></td> <td style="text-align: center">20.1%</td> </tr> <tr> <td style="text-align: left"><strong><code class="language-plaintext highlighter-rouge">mavleo96/whisper-accent-small.en</code></strong></td> <td style="text-align: center"> <strong>14.1%</strong> (+3.5%)</td> </tr> <tr> <td style="text-align: left"><strong><code class="language-plaintext highlighter-rouge">mavleo96/whisper-accent-medium.en</code></strong></td> <td style="text-align: center"> <strong>13.4%</strong> (+4.1%)</td> </tr> </tbody> </table> <div class="caption"> Table 1: Overall WER on the English Accent Dataset test split. Our models improve over all Whisper baselines including large-v3, despite being significantly smaller. </div> <h3 id="per-accent-wer-and-accent-classification-accuracy">Per-Accent WER and Accent Classification Accuracy</h3> <p>Improvements are observed across all 23 accent classes. The largest absolute reductions occur for accents with the highest baseline WER (Vietnamese, Spanish, French, Italian), where phonological distance from standard American English is greatest. The accent classifier achieves 85.1% accuracy on <code class="language-plaintext highlighter-rouge">whisper-accent-small.en</code> and <strong>95.7%</strong> on <code class="language-plaintext highlighter-rouge">whisper-accent-medium.en</code>.</p> <table> <thead> <tr> <th style="text-align: left">Accent</th> <th style="text-align: center">Whisper-small WER</th> <th style="text-align: center">Accent-small WER</th> <th style="text-align: center">Accent Acc.</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">American</td> <td style="text-align: center">14.2%</td> <td style="text-align: center">11.8%</td> <td style="text-align: center">91.3%</td> </tr> <tr> <td style="text-align: left">British</td> <td style="text-align: center">16.3%</td> <td style="text-align: center">13.1%</td> <td style="text-align: center">87.6%</td> </tr> <tr> <td style="text-align: left">Indian</td> <td style="text-align: center">22.1%</td> <td style="text-align: center">17.4%</td> <td style="text-align: center">88.2%</td> </tr> <tr> <td style="text-align: left">Spanish</td> <td style="text-align: center">25.4%</td> <td style="text-align: center">19.7%</td> <td style="text-align: center">82.1%</td> </tr> <tr> <td style="text-align: left">German</td> <td style="text-align: center">21.8%</td> <td style="text-align: center">17.0%</td> <td style="text-align: center">84.5%</td> </tr> <tr> <td style="text-align: left">French</td> <td style="text-align: center">24.6%</td> <td style="text-align: center">19.2%</td> <td style="text-align: center">81.7%</td> </tr> <tr> <td style="text-align: left">Scottish</td> <td style="text-align: center">19.3%</td> <td style="text-align: center">15.6%</td> <td style="text-align: center">88.9%</td> </tr> <tr> <td style="text-align: left">Dutch</td> <td style="text-align: center">20.5%</td> <td style="text-align: center">16.3%</td> <td style="text-align: center">83.4%</td> </tr> <tr> <td style="text-align: left">Irish</td> <td style="text-align: center">18.7%</td> <td style="text-align: center">15.0%</td> <td style="text-align: center">86.2%</td> </tr> <tr> <td style="text-align: left">Vietnamese</td> <td style="text-align: center">28.1%</td> <td style="text-align: center">22.3%</td> <td style="text-align: center">79.4%</td> </tr> <tr> <td style="text-align: left">Canadian</td> <td style="text-align: center">14.9%</td> <td style="text-align: center">12.2%</td> <td style="text-align: center">90.1%</td> </tr> <tr> <td style="text-align: left">Polish</td> <td style="text-align: center">23.2%</td> <td style="text-align: center">18.5%</td> <td style="text-align: center">80.8%</td> </tr> </tbody> </table> <div class="caption"> Table 2: Per-accent WER and classifier accuracy for a subset of accents (whisper-accent-small.en). Full 23-accent results in the repository. </div> <h3 id="ablation-ground-truth-vs-predicted-vs-random-accent-labels">Ablation: Ground-Truth vs. Predicted vs. Random Accent Labels</h3> <p>To isolate the contribution of accurate accent classification, we compare three conditioning modes at evaluation time.</p> <table> <thead> <tr> <th style="text-align: left">Conditioning</th> <th style="text-align: center">WER (small)</th> <th style="text-align: center">WER (medium)</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">Ground-truth accent label</td> <td style="text-align: center">13.6%</td> <td style="text-align: center">12.9%</td> </tr> <tr> <td style="text-align: left"><strong>Predicted accent label</strong></td> <td style="text-align: center"><strong>14.1%</strong></td> <td style="text-align: center"><strong>13.4%</strong></td> </tr> <tr> <td style="text-align: left">Random accent label</td> <td style="text-align: center">17.4%</td> <td style="text-align: center">17.2%</td> </tr> </tbody> </table> <div class="caption"> Table 3: WER under different accent conditioning strategies. Bold row is the operational (deployment) setting. </div> <p>Three findings stand out. <strong>First</strong>, random conditioning degrades performance to near-baseline Whisper WER, confirming that the gains are attributable to the specificity of the predicted accent label rather than a generic regularization effect. <strong>Second</strong>, the gap between predicted and ground-truth conditioning is only 0.5 pp, validating the end-to-end utility of the Stage 1 classifier. <strong>Third</strong>, the remaining gap to the ground-truth ceiling suggests that further improvements to accent classification could yield additional WER reductions.</p> <hr> <h2 id="accent-embedding-analysis">Accent Embedding Analysis</h2> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/whisper-accent/accent_embedding_cosine_similarity_whisper-accent-medium.en-480.webp 480w,/assets/img/whisper-accent/accent_embedding_cosine_similarity_whisper-accent-medium.en-800.webp 800w,/assets/img/whisper-accent/accent_embedding_cosine_similarity_whisper-accent-medium.en-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/whisper-accent/accent_embedding_cosine_similarity_whisper-accent-medium.en.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Cosine similarity heatmap of accent embeddings" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/whisper-accent/accent_embedding_umap_projection_whisper-accent-medium.en-480.webp 480w,/assets/img/whisper-accent/accent_embedding_umap_projection_whisper-accent-medium.en-800.webp 800w,/assets/img/whisper-accent/accent_embedding_umap_projection_whisper-accent-medium.en-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/whisper-accent/accent_embedding_umap_projection_whisper-accent-medium.en.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="UMAP projection of accent embeddings" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 2: Left — cosine similarity matrix of the 23 learned accent embeddings (whisper-accent-medium.en). Right — UMAP projection color-coded by broad linguistic/geographic region. Phonologically proximate accent families cluster naturally without explicit supervision. </div> <p>The cosine similarity heatmap reveals meaningful structure: Germanic accents (German, Dutch) are most similar to each other, as are the native British Isles varieties (British, Irish, Scottish, Northern Irish). Slavic accents (Czech, Polish, Slovak, Croatian, Slovene) form a coherent cluster in the UMAP projection. Vietnamese stands apart from all European accents, consistent with its typological distance.</p> <p>These geometries emerge from training on <strong>WER loss alone</strong> — the model was never explicitly supervised to cluster accents by linguistic family. This suggests that the AdaLN conditioning pressure encourages the accent embeddings to internalize phonological proximity as a useful organizational principle for decoder modulation.</p> <hr> <h2 id="discussion">Discussion</h2> <p><strong>Why AdaLN works for accent conditioning.</strong> LayerNorm controls the scale and mean of internal activations and has been shown to mediate significant representational control in generative models (missing reference). By conditioning these normalization statistics on a predicted accent label, AdaLN enables the model to softly “tune” the decoder’s representational manifold to the expected phonological properties of each accent, without rewriting attention pattern weights.</p> <p><strong>Generalization preserved.</strong> Because the encoder and decoder weights are entirely frozen, the model retains Whisper’s original WER on speech from accent classes not represented in training. The worst-case behavior under distribution shift is to predict an incorrect accent label and condition with the wrong embedding — as Table 3 shows, this still produces near-baseline Whisper performance rather than degrading below it.</p> <p><strong>Limitations.</strong> The current approach requires explicit accent labels in the training corpus. Additionally, the 23 accent classes are coarse categories; within-class variation (e.g., regional varieties of Indian English) is not captured. Future work could explore a continuous accent embedding space trained via contrastive objectives rather than discrete classification.</p> <hr> <h2 id="checkpoints--code">Checkpoints &amp; Code</h2> <p>Pretrained checkpoints are available on the Hugging Face Hub:</p> <ul> <li><a href="https://huggingface.co/mavleo96/whisper-accent-small.en" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">mavleo96/whisper-accent-small.en</code></a></li> <li><a href="https://huggingface.co/mavleo96/whisper-accent-medium.en" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">mavleo96/whisper-accent-medium.en</code></a></li> </ul> <p>Training and evaluation code: <a href="https://github.com/mavleo96/whisper-accent" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">github.com/mavleo96/whisper-accent</code></a></p> </article> <h2>References</h2> <div class="publications"> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Vijayabharathi Murugan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>